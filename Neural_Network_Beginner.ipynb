{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "**Last edited**: 2017-11-04 14:19:48 \n",
    "\n",
    "[nbviewer](http://nbviewer.jupyter.org/github/nuclth/Kaggle_Digit_Recognizer/blob/master/Neural_Network_Beginner.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook to classify handwritten digits in the MNIST data set using a simple neural network. Most of the code and implementation are borrowed from Chapters 1 and 2 of Michael Nielsen's [book](http://neuralnetworksanddeeplearning.com/) on neural networks and deep learning as well as the code hosted on his [github page](https://github.com/mnielsen/neural-networks-and-deep-learning) (note that it is all written in python 2). Also useful is a python 3 implementation of the same code by [Michał Dobrzanski](https://github.com/MichalDanielDobrzanski/DeepLearningPython35). The actual implementation code for this notebook is hidden in the file, `network.py` in the `src` subdirectory. The MNIST data we use is downloaded from [Kaggle](https://www.kaggle.com/c/digit-recognizer/data).\n",
    "\n",
    "This problem is classified as a supervised classification problem. Supervised because we are inputting some subset of the MNIST data set to guide our model, and classification because we ultimately want to decide which digit the image is referring to in the range 0 - 9 inclusive. Each image consists of 28 pixels by 28 pixel, 784 pixels in total, with each pixel taking a possible value of 0 to 255 (0 = white, 255 = black, gray for everything in between).\n",
    "\n",
    "First let's import the relevant libraries:\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T15:30:38.758978Z",
     "start_time": "2017-11-05T15:30:34.978364Z"
    }
   },
   "outputs": [],
   "source": [
    "# third party libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import network module\n",
    "import src.network as network\n",
    "\n",
    "# import plotting/visualization libraries\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set custom plotting values\n",
    "mpl.rcParams['figure.figsize'] = (8,8)\n",
    "mpl.rcParams['lines.linewidth'] = 4\n",
    "mpl.rcParams['axes.labelsize'] = 20\n",
    "mpl.rcParams['xtick.labelsize'] = 20 \n",
    "mpl.rcParams['ytick.labelsize'] = 20 \n",
    "mpl.rcParams['xtick.major.size'] = 10\n",
    "mpl.rcParams['ytick.major.size'] = 10\n",
    "mpl.rcParams['lines.markersize'] = 1000\n",
    "mpl.rcParams['legend.fontsize'] = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Next we import the data that we previously downloaded. Note that the training data has one column with the image label and then 784 columns with a number between 0 and 255 to denote pixel activation. Our test set is similar only it is missing the label column as this is what we are trying to predict.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T15:30:43.605527Z",
     "start_time": "2017-11-05T15:30:38.760276Z"
    }
   },
   "outputs": [],
   "source": [
    "training_data = pd.read_csv('./data/train.csv')\n",
    "test_data = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T15:30:43.666651Z",
     "start_time": "2017-11-05T15:30:43.606705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "\n",
       "[3 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T15:30:43.844318Z",
     "start_time": "2017-11-05T15:30:43.667830Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "\n",
       "[3 rows x 784 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Let's take a quick look to see what the images look like. We arbitrarily choose the second image in the training set (index from zero, so value 1 is the second image). The image is printed with 28 pixels to a row so as to make the digit in the image obvious. \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T15:30:44.212029Z",
     "start_time": "2017-11-05T15:30:43.845445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0   0   0   0   0   0  18  30 137 137 192  86  72   1   0   0   0   0   0   0   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0   0   0   0  13  86 250 254 254 254 254 217 246 151  32   0   0   0   0   0   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0   0   0  16 179 254 254 254 254 254 254 254 254 254 231  54  15   0   0   0   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0   0   0  72 254 254 254 254 254 254 254 254 254 254 254 254 104   0   0   0   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0   0  61 191 254 254 254 254 254 109  83 199 254 254 254 254 243  85   0   0   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0   0 172 254 254 254 202 147 147  45   0  11  29 200 254 254 254 171   0   0   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0   1 174 254 254  89  67   0   0   0   0   0   0 128 252 254 254 212  76   0   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0  47 254 254 254  29   0   0   0   0   0   0   0   0  83 254 254 254 153   0   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0  80 254 254 240  24   0   0   0   0   0   0   0   0  25 240 254 254 153   0   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0  64 254 254 186   7   0   0   0   0   0   0   0   0   0 166 254 254 224  12   0   0   0   0 \n",
      "\n",
      "  0   0   0   0  14 232 254 254 254  29   0   0   0   0   0   0   0   0   0  75 254 254 254  17   0   0   0   0 \n",
      "\n",
      "  0   0   0   0  18 254 254 254 254  29   0   0   0   0   0   0   0   0   0  48 254 254 254  17   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   2 163 254 254 254  29   0   0   0   0   0   0   0   0   0  48 254 254 254  17   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0  94 254 254 254 200  12   0   0   0   0   0   0   0  16 209 254 254 150   1   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0  15 206 254 254 254 202  66   0   0   0   0   0  21 161 254 254 245  31   0   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0   0  60 212 254 254 254 194  48  48  34  41  48 209 254 254 254 171   0   0   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0   0   0  86 243 254 254 254 254 254 233 243 254 254 254 254 254  86   0   0   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0   0   0   0 114 254 254 254 254 254 254 254 254 254 254 239  86  11   0   0   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0   0   0   0  13 182 254 254 254 254 254 254 254 254 243  70   0   0   0   0   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0   0   0   0   0   8  76 146 254 255 254 255 146  19  15   0   0   0   0   0   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "\n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 "
     ]
    }
   ],
   "source": [
    "network.print_image (training_data, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "It's pretty obvious that this image should correspond to a zero, but let's check the label itself just to be sure,\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T15:30:44.216204Z",
     "start_time": "2017-11-05T15:30:44.213324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Label 0\n"
     ]
    }
   ],
   "source": [
    "# .iloc[1,0] chooses the second row (second image) and \n",
    "# first column (label) of the training dataset.\n",
    "print ('Image Label {}'.format(training_data.iloc[1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Bingo.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Now let's actually see how many images we're working with in each set and start manipulating the data.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T15:30:44.388382Z",
     "start_time": "2017-11-05T15:30:44.217628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42000 entries, 0 to 41999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 251.5 MB\n",
      "\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28000 entries, 0 to 27999\n",
      "Columns: 784 entries, pixel0 to pixel783\n",
      "dtypes: int64(784)\n",
      "memory usage: 167.5 MB\n"
     ]
    }
   ],
   "source": [
    "training_data.info() ; print('\\n')\n",
    "test_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "We see that our training set contains 42,000 images while our test set has 28,000 images. Note also that as expected, we have the correct number of columns for each (785 and 784 respectively).\n",
    "\n",
    "Let's separate our training data into a training set and a validation set. The training set will be used to fit our model and then we'll validate the model with the remaining data in the validation set. For simplicity, we fit using the first 40,000 images in the training set and validate against the last 2,000 entries. For ease of working with the data, we pull it from our dataframe into a numpy array and then format it using the function `format_data`. This is done for our training and validation set (for more details on the output format, consult the function defined in `network.py`). \n",
    "\n",
    "For our test data, we follow the same procedure but perform the formatting in the cell below and obviously do not have a label for each image. Note that the code *requires* a shape of (784,1) rather than (784,) for correct performance of numpy routines. Also note that we normalize the pixel values to be in the range $[0,1]$ rather than $[0,255]$.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T15:30:45.159105Z",
     "start_time": "2017-11-05T15:30:44.389571Z"
    }
   },
   "outputs": [],
   "source": [
    "# create data sets\n",
    "train_ar = np.array(training_data.iloc[:40000])\n",
    "valid_ar = np.array(training_data.iloc[40000:42000])\n",
    "test_ar  = np.array(test_data)\n",
    "\n",
    "# format training and validation set\n",
    "train_list = network.format_data (train_ar)\n",
    "valid_list = network.format_data (valid_ar)\n",
    "train_list = list(train_list)\n",
    "valid_list = list(valid_list)\n",
    "\n",
    "# format the test data\n",
    "test_list = [np.reshape(x, (784,1))/255 for x in test_ar]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Now let's create a neural network. We call the class name `Network` and give our network one hidden layer with 30 nodes. The choice of one hidden layer and the exact number of nodes is arbitrary at this point. Note that we also have an initial layer of 784 nodes (one node per pixel) and an output layer of 10 nodes, one for each possible digit $[0,9]$. Note that for this choice of layers and nodes, we have two weight matrices of dimensions (30, 784) and (10, 30). Our biases on each layer are vectors of dimension (30, 1) and (10, 1). \n",
    "\n",
    "We then perform stochastic gradient descent on the network by calling the class function `SGD`. The idea is that this routine calculates the derivatives of a defined cost function as a function of the weights and biases. We tune the weights and biases so as to minimize this cost function, here defined as the difference between the output on the last layer of 10 nodes and the correct result. For example, suppose our network for image $i$ with label 2 gives the output,\n",
    "\n",
    "$$\\text{approx}_i = [0, 0.2, 0.7, 0, 0.1, 0, 0, 0, 0, 0.3] \\enspace .$$\n",
    "\n",
    "Our cost function for this output is then given as the difference between it and the exact output ,\n",
    "\n",
    "$$\\text{exact}_i = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] \\enspace ,$$\n",
    "\n",
    "$$\\text{cost}_i = \\text{approx}_i - \\text{exact}_i \\enspace ,$$\n",
    "\n",
    "where only the 3rd entry changes as that corresponds to digit 2 (again indexing starts at 0).\n",
    "\n",
    "\n",
    "\n",
    "The gradient descent is costly to calculate for all images, so we sample this stochastically with some subset of images. The gradient is also multiplied by some number (called the learning parameter) to give greater or lesser importance to it. A small learning parameter means we move more slowly (but surely) through this space while a bigger parameter lets us move quicker (but perhaps less accurately). This whole process is then repeated for several 'epochs' so as to train the network and optimize the biases/weights. After each epoch, we output the number of images in the validation set that have been correctly classified. For much more detail, again see the book by Michael Nielsen (chapters 1 and 2). \n",
    "\n",
    "The `SGD` function is called with 30 epochs of training, 10 images chosen for the gradient averaging, and a learning parameter of 3. At this point, these choices are arbitrary and are not necessarily optimized. The results of each epoch of training are stored in `eval_list` and the ultimate output after all epochs are finished are the trained biases and weights of the network.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T19:24:31.748132Z",
     "start_time": "2017-11-04T19:21:59.000165Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 1789 / 2000\n",
      "Epoch 1: 1824 / 2000\n",
      "Epoch 2: 1836 / 2000\n",
      "Epoch 3: 1842 / 2000\n",
      "Epoch 4: 1868 / 2000\n",
      "Epoch 5: 1875 / 2000\n",
      "Epoch 6: 1854 / 2000\n",
      "Epoch 7: 1876 / 2000\n",
      "Epoch 8: 1868 / 2000\n",
      "Epoch 9: 1873 / 2000\n",
      "Epoch 10: 1863 / 2000\n",
      "Epoch 11: 1868 / 2000\n",
      "Epoch 12: 1874 / 2000\n",
      "Epoch 13: 1871 / 2000\n",
      "Epoch 14: 1871 / 2000\n",
      "Epoch 15: 1881 / 2000\n",
      "Epoch 16: 1880 / 2000\n",
      "Epoch 17: 1871 / 2000\n",
      "Epoch 18: 1880 / 2000\n",
      "Epoch 19: 1875 / 2000\n",
      "Epoch 20: 1878 / 2000\n",
      "Epoch 21: 1871 / 2000\n",
      "Epoch 22: 1869 / 2000\n",
      "Epoch 23: 1868 / 2000\n",
      "Epoch 24: 1874 / 2000\n",
      "Epoch 25: 1873 / 2000\n",
      "Epoch 26: 1883 / 2000\n",
      "Epoch 27: 1871 / 2000\n",
      "Epoch 28: 1873 / 2000\n",
      "Epoch 29: 1879 / 2000\n"
     ]
    }
   ],
   "source": [
    "# list values denotes number of nodes in each layer\n",
    "net = network.Network([784, 30, 10])\n",
    "\n",
    "# create blank list to store results\n",
    "eval_list = []\n",
    "\n",
    "# call SGD function and store final biases and weights\n",
    "(biases, weights) = net.SGD(train_list, 30, 10, 3.0, test_data = valid_list, store_eval = eval_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "We can plot his information to see the rapid improvement with each epoch of training. After a few epochs, the \n",
    "network saturates around a given accuracy. \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-04T19:24:32.889964Z",
     "start_time": "2017-11-04T19:24:31.749304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAicAAAICCAYAAAAUMW1YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naorFiSRJasr/AlaZLNYbkVJkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f263c8fa8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epoch_list = [a for a in range (0,len(eval_list))]\n",
    "\n",
    "# plot the function and data\n",
    "plt.scatter(epoch_list, eval_list, s=40, label=\"Neural Network\")\n",
    "plt.xlabel (\"Epoch\")\n",
    "plt.ylabel (\"Correct ratio\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Now we're ready to test our neural network on the test data for which we don't have a label. As the `feedforward` function defined in our `Network` class relies on using the class defined `biases` and `weights`, let's define our own version here. This function takes in the 784 input activations (`a`)for a given image and then cycles through the network with our trained biases & weights. \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T15:31:27.495476Z",
     "start_time": "2017-11-05T15:31:27.489446Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def feedforward(a, biases, weights):\n",
    "    for b, w in zip(biases, weights):\n",
    "        a = network.sigmoid(np.dot(w, a)+b)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Now we just proceed as before only using the full set of training data on the network.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T15:42:27.156341Z",
     "start_time": "2017-11-05T15:42:14.769704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 complete\n",
      "Epoch 1 complete\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1130f02a4c5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# call SGD function and store final biases and weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mfull_biases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_weights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_train_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/Kaggle/Digit_Recognizer/src/network.py\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(self, train_data, epochs, mini_batch_size, eta, test_data, store_eval)\u001b[0m\n\u001b[1;32m     79\u001b[0m                 for k in range(0, n, mini_batch_size)]\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmini_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmini_batches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_mini_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmini_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0mtrained_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mtrained_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Kaggle/Digit_Recognizer/src/network.py\u001b[0m in \u001b[0;36mupdate_mini_batch\u001b[0;34m(self, mini_batch, eta)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mnabla_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmini_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mdelta_nabla_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_nabla_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mnabla_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdnb\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdnb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnabla_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_nabla_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mnabla_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnw\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdnw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdnw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnabla_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_nabla_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Kaggle/Digit_Recognizer/src/network.py\u001b[0m in \u001b[0;36mbackprop\u001b[0;34m(self, image, value)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0msp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid_prime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mnabla_b\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Kaggle/Digit_Recognizer/src/network.py\u001b[0m in \u001b[0;36msigmoid_prime\u001b[0;34m(z)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid_prime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;34m\"\"\"Derivative of the sigmoid function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/Kaggle/Digit_Recognizer/src/network.py\u001b[0m in \u001b[0;36msigmoid\u001b[0;34m(z)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;34m\"\"\"The sigmoid function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# list values denotes number of nodes in each layer\n",
    "full_net = network.Network([784, 30, 10])\n",
    "\n",
    "# create data sets\n",
    "full_train_ar = np.array(training_data.iloc[:42000])\n",
    "\n",
    "# format training and validation set\n",
    "full_train_list = network.format_data (full_train_ar)\n",
    "full_train_list = list(full_train_list)\n",
    "\n",
    "# call SGD function and store final biases and weights\n",
    "(full_biases, full_weights) = full_net.SGD(full_train_list, 30, 10, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-05T15:34:50.103943Z",
     "start_time": "2017-11-05T15:34:50.085104Z"
    }
   },
   "outputs": [],
   "source": [
    "# create series 1 to 28,000\n",
    "imageid = pd.Series(range(1,len(test_list)+1))\n",
    "\n",
    "# output predicted image label\n",
    "predictions_test = [np.argmax(feedforward(image, biases, weights)) for image in test_list]\n",
    "\n",
    "# create dataframe to hold id and predicted label\n",
    "output = pd.DataFrame({'ImageId' : imageid, 'Label' : predictions_test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Let's make sure everything looks ok and that we built our dataframe correctly.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      9\n",
       "4        5      3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28000 entries, 0 to 27999\n",
      "Data columns (total 2 columns):\n",
      "ImageId    28000 non-null int32\n",
      "Label      28000 non-null int64\n",
      "dtypes: int32(1), int64(1)\n",
      "memory usage: 328.2 KB\n"
     ]
    }
   ],
   "source": [
    "output.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Looks good so let's output to csv and submit to kaggle.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output.to_csv('predictions_digits.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Submission to kaggle then gives an accuracy score of around 94.514%, meaning we only misclassified around 5 out of every 100 images. A very basic benchmark to compare to is picking labels at random (accuracy of 10%) and other simple classifier algorithms like support vector machines. The absolute accuracy and variability of the final neural network score can be improved by building extensions on to our simple network and will be considered in another notebook.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Baseline (under construction, move to new notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a support vector machine baseline to see where we sit (this may take several minutes to execute)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-30T01:36:39.811088Z",
     "start_time": "2017-10-30T01:36:01.854842Z"
    }
   },
   "source": [
    "baseline = svm.SVC()\n",
    "    \n",
    "# take slice \n",
    "input_svm = [image[1] for image in train_list]\n",
    "output_svm = [image[0] for image in train_list] \n",
    "    \n",
    "input_svm = list(map(np.ravel, input_svm))\n",
    " \n",
    "print (input_svm)    \n",
    "\n",
    "testing_in = [image[1] for image in valid_list]\n",
    "testing_out = [image[0] for image in valid_list]\n",
    "    \n",
    "testing_in = list(map(np.ravel, testing_in))\n",
    "\n",
    "\n",
    "baseline.fit(input_svm, output_svm)\n",
    "\n",
    "predictions = [int(a) for a in baseline.predict(testing_in)]\n",
    "    \n",
    "correct = sum(int(a==y) for a, y in zip(predictions, testing_out))\n",
    "    \n",
    "print (\"{} of {} values correct, {}%\".format(correct, len(testing_out), correct/(len(testing_out))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somewhere in the low 90% area. Not too shabby but let's see if we can do better with a neural network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "none",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
